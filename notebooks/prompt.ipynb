{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/melaku/.local/lib/python3.10/site-packages (1.31.0)\n",
      "Requirement already satisfied: langchain in /home/melaku/.local/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: python-dotenv in /usr/lib/python3/dist-packages (0.19.2)\n",
      "Requirement already satisfied: tqdm>4 in /home/melaku/.local/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/melaku/.local/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/melaku/.local/lib/python3.10/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: sniffio in /home/melaku/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/melaku/.local/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/melaku/.local/lib/python3.10/site-packages (from openai) (2.7.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/melaku/.local/lib/python3.10/site-packages (from langchain) (0.1.71)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/melaku/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/melaku/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/melaku/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/melaku/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/melaku/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/melaku/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/melaku/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: certifi in /home/melaku/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/melaku/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/melaku/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/melaku/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/melaku/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/melaku/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/melaku/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/melaku/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/melaku/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/melaku/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/melaku/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "\"Create a memorable slogan for an eco-friendly product in just a few words!\"\n",
      "Response: \n",
      "\n",
      "\"Go green, save the planet!\" \n",
      "\n",
      "\n",
      "Prompt:  \n",
      "\"Create a memorable marketing slogan for a product that prioritizes sustainability and eco-friendliness.\" \n",
      "Response: \n",
      "\n",
      "\"Go Green and Feel Good: Choose Our Sustainable Product!\"\n",
      "\n",
      "Prompt: \n",
      "\"Create a catchy slogan for an eco-friendly product that appeals to young adults!\"\n",
      "Response: \n",
      "\n",
      "\"Join the green team, keep the planet clean!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Cell 3: Define Prompt Generation Logic\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Initialize OpenAI with API key\n",
    "llm = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "def generate_prompts_and_responses(user_input, scenarios):\n",
    "    template = \"\"\"\n",
    "    User input: {user_input}\n",
    "    Scenario: {scenario}\n",
    "    Generate a prompt for the above scenario.\n",
    "    \"\"\"\n",
    "    prompts_and_responses = []\n",
    "    for scenario in scenarios:\n",
    "        # Generate the prompt\n",
    "        prompt_template = PromptTemplate(template=template, input_variables=[\"user_input\", \"scenario\"])\n",
    "        chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "        generated_prompt = chain.run(user_input=user_input, scenario=scenario)\n",
    "        \n",
    "        # Use the generated prompt to get a response\n",
    "        response_chain = LLMChain(llm=llm, prompt=PromptTemplate(template=\"{prompt}\", input_variables=[\"prompt\"]))\n",
    "        response = response_chain.run(prompt=generated_prompt)\n",
    "        \n",
    "        prompts_and_responses.append((generated_prompt, response))\n",
    "    return prompts_and_responses\n",
    "\n",
    "# Cell 4: Example Usage\n",
    "user_input = \"Generate a marketing slogan for an eco-friendly product\"\n",
    "scenarios = [\"short and catchy\", \"emphasizes sustainability\", \"targeted at young adults\"]\n",
    "generated_prompts_and_responses = generate_prompts_and_responses(user_input, scenarios)\n",
    "\n",
    "for prompt, response in generated_prompts_and_responses:\n",
    "    print(\"Prompt:\", prompt)\n",
    "    print(\"Response:\", response)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m919.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m812.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/melaku/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "\n",
      "\"Create a punchy tagline for an environmentally conscious product that will stick in people's minds.\"\n",
      "Score: 0.13\n",
      "\n",
      "Prompt: \n",
      "\n",
      "\"Create a memorable tagline for an environmentally friendly product that highlights its commitment to sustainability.\"\n",
      "Score: 0.20\n",
      "\n",
      "Prompt: \n",
      "\n",
      "\"Create a catchy marketing slogan for an eco-friendly product that will appeal to young adults and make a positive impact on the environment.\"\n",
      "Score: 0.38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.base import Chain\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def generate_prompts(user_input, scenarios):\n",
    "    template = \"Given the user input: '{user_input}' and scenario: '{scenario}', generate a relevant prompt.\"\n",
    "    prompts = []\n",
    "    for scenario in scenarios:\n",
    "        prompt_template = PromptTemplate(template=template, input_variables=[\"user_input\", \"scenario\"])\n",
    "        chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "        result = chain.run(user_input=user_input, scenario=scenario)\n",
    "        prompts.append(result)\n",
    "    return prompts\n",
    "\n",
    "def evaluate_prompts(user_input, prompts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([user_input] + prompts)\n",
    "    user_input_vector = vectors[0]\n",
    "    prompt_vectors = vectors[1:]\n",
    "\n",
    "    similarities = cosine_similarity(user_input_vector, prompt_vectors)\n",
    "    evaluation_scores = similarities.flatten()\n",
    "    return evaluation_scores\n",
    "\n",
    "user_input = \"Generate a marketing slogan for an eco-friendly product\"\n",
    "scenarios = [\"short and catchy\", \"emphasizes sustainability\", \"targeted at young adults\"]\n",
    "\n",
    "# Generate prompts\n",
    "generated_prompts = generate_prompts(user_input, scenarios)\n",
    "\n",
    "# Evaluate prompts\n",
    "evaluation_scores = evaluate_prompts(user_input, generated_prompts)\n",
    "\n",
    "# Display prompts and their evaluation scores\n",
    "for prompt, score in zip(generated_prompts, evaluation_scores):\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Score: {score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "\n",
      "\"Get ready to go green with our eco-friendly product - the perfect solution for a sustainable lifestyle!\"\n",
      "Score: 0.24\n",
      "ELO Rating: 1549.00\n",
      "\n",
      "Prompt: \n",
      "\n",
      "\"Create a catchy marketing slogan that promotes the eco-friendliness and sustainability of our product!\"\n",
      "Score: 0.27\n",
      "ELO Rating: 1560.00\n",
      "\n",
      "Prompt: \n",
      "\n",
      "\"Create a catchy tagline promoting a sustainable product that will make young adults go green!\"\n",
      "Score: 0.04\n",
      "ELO Rating: 1489.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to simulate matchups between prompts\n",
    "def monte_carlo_matchmaking(prompts, evaluation_scores, num_simulations=100):\n",
    "    num_prompts = len(prompts)\n",
    "    wins = np.zeros(num_prompts)\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        for i in range(num_prompts):\n",
    "            for j in range(i + 1, num_prompts):\n",
    "                if random.random() < evaluation_scores[i] / (evaluation_scores[i] + evaluation_scores[j]):\n",
    "                    wins[i] += 1\n",
    "                else:\n",
    "                    wins[j] += 1\n",
    "\n",
    "    return wins\n",
    "\n",
    "# Function to calculate the expected score\n",
    "def expected_score(rating1, rating2):\n",
    "    return 1 / (1 + 10 ** ((rating2 - rating1) / 400))\n",
    "\n",
    "# Function to update ELO ratings\n",
    "def update_elo_ratings(ratings, wins, num_simulations=100):\n",
    "    K = 32\n",
    "    for i in range(len(ratings)):\n",
    "        for j in range(len(ratings)):\n",
    "            if i != j:\n",
    "                expected_i = expected_score(ratings[i], ratings[j])\n",
    "                actual_i = wins[i] / num_simulations\n",
    "                ratings[i] += K * (actual_i - expected_i)\n",
    "    return ratings\n",
    "\n",
    "# Main execution\n",
    "user_input = \"Generate a marketing slogan for an eco-friendly product\"\n",
    "scenarios = [\"short and catchy\", \"emphasizes sustainability\", \"targeted at young adults\"]\n",
    "\n",
    "# Generate prompts\n",
    "generated_prompts = generate_prompts(user_input, scenarios)\n",
    "\n",
    "# Evaluate prompts\n",
    "evaluation_scores = evaluate_prompts(user_input, generated_prompts)\n",
    "\n",
    "# Monte Carlo matchmaking\n",
    "num_simulations = 100\n",
    "wins = monte_carlo_matchmaking(generated_prompts, evaluation_scores, num_simulations)\n",
    "\n",
    "# Initial ELO ratings\n",
    "initial_ratings = np.full(len(generated_prompts), 1500)\n",
    "\n",
    "# Update ELO ratings based on matchmaking results\n",
    "final_ratings = update_elo_ratings(initial_ratings, wins, num_simulations)\n",
    "\n",
    "# Display prompts, their evaluation scores, and ELO ratings\n",
    "for prompt, score, rating in zip(generated_prompts, evaluation_scores, final_ratings):\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Score: {score:.2f}\")\n",
    "    print(f\"ELO Rating: {rating:.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
